{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                  0.2654          0.4601                  0.11890     0.0  \n",
       "1                  0.1860          0.2750                  0.08902     0.0  \n",
       "2                  0.2430          0.3613                  0.08758     0.0  \n",
       "3                  0.2575          0.6638                  0.17300     0.0  \n",
       "4                  0.1625          0.2364                  0.07678     0.0  \n",
       "..                    ...             ...                      ...     ...  \n",
       "564                0.2216          0.2060                  0.07115     0.0  \n",
       "565                0.1628          0.2572                  0.06637     0.0  \n",
       "566                0.1418          0.2218                  0.07820     0.0  \n",
       "567                0.2650          0.4087                  0.12400     0.0  \n",
       "568                0.0000          0.2871                  0.07039     1.0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "np.random.seed(1)\n",
    "cancer = load_breast_cancer()\n",
    "columns = np.append(cancer[\"feature_names\"], \"target\")\n",
    "data = np.column_stack((cancer[\"data\"], cancer[\"target\"]))\n",
    "df = pd.DataFrame(data=data, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 569) (1, 569)\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(\"target\", axis = 1).to_numpy()#convert the data into numpy array\n",
    "y = df.get(\"target\").to_numpy() #convert series(569,) to numpy array(569,1)\n",
    "y = y.reshape(569, 1)\n",
    "x = np.transpose(x)\n",
    "y = np.transpose(y)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 400) (1, 400) (30, 169) (1, 169)\n"
     ]
    }
   ],
   "source": [
    "#Let the first 400 features be the training set and the remaining be the test set\n",
    "x_train = x[0:,0:400]\n",
    "y_train = y[:,0:400]\n",
    "x_test = x[:,400:]\n",
    "y_test = y[:,400:]\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(params):\n",
    "    #W = np.random.randn(params, 1)*0.01\n",
    "    W= np.zeros((params,1))\n",
    "    b= 0\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    #z = Wx+b\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(W, b, X, Y):\n",
    "    A = sigmoid(np.dot(W.T, X)+b)\n",
    "    cost = (np.sum(np.multiply(Y, np.log(A)) + np.multiply((1-Y), np.log(1-A))))/-X.shape[1]\n",
    "    dW = (np.dot(X, (A-Y).T))/X.shape[1]\n",
    "    db = (np.sum((A-Y).T))/X.shape[1]\n",
    "    \n",
    "    cost = np.squeeze(cost)\n",
    "    grads = {\n",
    "        \"dW\" : dW,\n",
    "        \"db\" : db\n",
    "    }\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(x, y, iterations, lr):\n",
    "    W, b = initialize(x.shape[0])\n",
    "    costs = []\n",
    "    for i in range(iterations):\n",
    "        grads, cost = forward_prop(W, b, x, y)\n",
    "        dW = grads[\"dW\"]\n",
    "        db = grads[\"db\"]\n",
    "        W = W-lr*dW\n",
    "        b = b-lr*db\n",
    "        if i%250==0:\n",
    "            costs.append(cost)\n",
    "    params = {\"W\": W,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dW\": dW,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    dm = y-y_hat\n",
    "    count = np.count_nonzero(dm, axis=1)\n",
    "    return count/y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(W, b, x):\n",
    "    z = np.dot(W.T, x)+b\n",
    "    a = sigmoid(z)\n",
    "    ans = np.where(a>0.5, 1, 0)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,g,c=optimize(x_scaled, y_train, 50000, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-74d8fde65921>:3: RuntimeWarning: overflow encountered in exp\n",
      "  s = 1/(1+np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "y_hat = predict(p[\"W\"], p[\"b\"], x_train)\n",
    "\n",
    "y_hat_test = predict(p[\"W\"], p[\"b\"], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train set: 92.0 %\n",
      "Accuracy for test set: 95.26627218934911 %\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(y_hat, y_train)\n",
    "perc_acc = np.squeeze((1-acc)*100)\n",
    "test_acc = np.squeeze((1-accuracy(y_hat_test, y_test))*100)\n",
    "print(\"Accuracy for train set: {} %\".format(perc_acc))\n",
    "print(\"Accuracy for test set: {} %\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6931471805599452,\n",
       " 0.25875403729554924,\n",
       " 0.23386524968668687,\n",
       " 0.22040810472550298,\n",
       " 0.21225568259307293,\n",
       " 0.20683060808750608,\n",
       " 0.20295763114534218,\n",
       " 0.2000420343097986,\n",
       " 0.1977539566651604,\n",
       " 0.1958968136555316,\n",
       " 0.1943467431375989,\n",
       " 0.19302220246964003,\n",
       " 0.19186757557835726,\n",
       " 0.19084380694554748,\n",
       " 0.18992279000158072,\n",
       " 0.18908386943724223,\n",
       " 0.18831158724021668,\n",
       " 0.18759418828029925,\n",
       " 0.18692260483901568,\n",
       " 0.1862897516413424,\n",
       " 0.1856900271340627,\n",
       " 0.18511895472521536,\n",
       " 0.18457292082589652,\n",
       " 0.18404898099172903,\n",
       " 0.18354471470925302,\n",
       " 0.18305811541316225,\n",
       " 0.18258750634096735,\n",
       " 0.1821314755539353,\n",
       " 0.1816888253252304,\n",
       " 0.18125853240206843,\n",
       " 0.18083971657160755,\n",
       " 0.1804316156204465,\n",
       " 0.18003356525505917,\n",
       " 0.17964498289939057,\n",
       " 0.17926535454321552,\n",
       " 0.178894224006425,\n",
       " 0.17853118412814659,\n",
       " 0.17817586949831057,\n",
       " 0.17782795043206165,\n",
       " 0.17748712795090563,\n",
       " 0.17715312958346985,\n",
       " 0.17682570583679025,\n",
       " 0.1765046272187344,\n",
       " 0.17618968171547764,\n",
       " 0.17588067264634397,\n",
       " 0.17557741683290234,\n",
       " 0.17527974303083368,\n",
       " 0.17498749058237334,\n",
       " 0.17470050825461506,\n",
       " 0.174418653234992,\n",
       " 0.1741417902601414,\n",
       " 0.17386979085834148,\n",
       " 0.17360253268896111,\n",
       " 0.1733398989650294,\n",
       " 0.17308177794723428,\n",
       " 0.17282806249946586,\n",
       " 0.1725786496975382,\n",
       " 0.17233344048396465,\n",
       " 0.17209233936271873,\n",
       " 0.1718552541287847,\n",
       " 0.171622095628042,\n",
       " 0.17139277754365154,\n",
       " 0.17116721620563677,\n",
       " 0.17094533042080273,\n",
       " 0.1707270413205148,\n",
       " 0.17051227222418727,\n",
       " 0.17030094851660757,\n",
       " 0.17009299753746554,\n",
       " 0.16988834848165824,\n",
       " 0.1696869323091242,\n",
       " 0.1694886816631108,\n",
       " 0.16929353079591372,\n",
       " 0.16910141550124436,\n",
       " 0.16891227305248013,\n",
       " 0.1687260421461427,\n",
       " 0.16854266285002495,\n",
       " 0.1683620765554563,\n",
       " 0.16818422593325316,\n",
       " 0.16800905489295664,\n",
       " 0.16783650854500146,\n",
       " 0.16766653316550326,\n",
       " 0.16749907616338672,\n",
       " 0.1673340860496067,\n",
       " 0.16717151240824357,\n",
       " 0.16701130586927931,\n",
       " 0.16685341808288023,\n",
       " 0.166697801695034,\n",
       " 0.16654441032440517,\n",
       " 0.1663931985402863,\n",
       " 0.16624412184153944,\n",
       " 0.16609713663643055,\n",
       " 0.16595220022327348,\n",
       " 0.16580927077180632,\n",
       " 0.1656683073052358,\n",
       " 0.1655292696828871,\n",
       " 0.1653921185834094,\n",
       " 0.16525681548848792,\n",
       " 0.16512332266702268,\n",
       " 0.16499160315973568,\n",
       " 0.164861620764176,\n",
       " 0.16473334002009107,\n",
       " 0.16460672619514127,\n",
       " 0.1644817452709343,\n",
       " 0.1643583639293578,\n",
       " 0.16423654953919573,\n",
       " 0.16411627014300997,\n",
       " 0.1639974944442752,\n",
       " 0.16388019179475394,\n",
       " 0.16376433218210146,\n",
       " 0.16364988621769144,\n",
       " 0.16353682512465312,\n",
       " 0.16342512072611395,\n",
       " 0.16331474543363936,\n",
       " 0.16320567223586582,\n",
       " 0.1630978746873217,\n",
       " 0.16299132689742987,\n",
       " 0.16288600351968982,\n",
       " 0.16278187974103644,\n",
       " 0.16267893127136834,\n",
       " 0.1625771343332483,\n",
       " 0.16247646565176851,\n",
       " 0.16237690244458136,\n",
       " 0.16227842241209253,\n",
       " 0.16218100372781316,\n",
       " 0.16208462502887236,\n",
       " 0.1619892654066849,\n",
       " 0.16189490439777499,\n",
       " 0.1618015219747527,\n",
       " 0.16170909853744395,\n",
       " 0.16161761490416887,\n",
       " 0.16152705230317133,\n",
       " 0.16143739236419527,\n",
       " 0.16134861711020698,\n",
       " 0.16126070894926336,\n",
       " 0.16117365066652298,\n",
       " 0.1610874254163987,\n",
       " 0.16100201671485304,\n",
       " 0.16091740843183008,\n",
       " 0.1608335847838274,\n",
       " 0.16075053032660327,\n",
       " 0.1606682299480191,\n",
       " 0.16058666886101483,\n",
       " 0.1605058325967167,\n",
       " 0.1604257069976749,\n",
       " 0.16034627821123018,\n",
       " 0.16026753268300728,\n",
       " 0.16018945715053462,\n",
       " 0.16011203863698664,\n",
       " 0.1600352644450497,\n",
       " 0.1599591221509079,\n",
       " 0.1598835995983479,\n",
       " 0.15980868489298117,\n",
       " 0.15973436639658187,\n",
       " 0.15966063272153808,\n",
       " 0.15958747272541657,\n",
       " 0.15951487550563584,\n",
       " 0.15944283039425045,\n",
       " 0.1593713269528405,\n",
       " 0.1593003549675073,\n",
       " 0.15922990444397236,\n",
       " 0.15915996560277854,\n",
       " 0.15909052887459146,\n",
       " 0.15902158489559887,\n",
       " 0.15895312450300753,\n",
       " 0.15888513873063473,\n",
       " 0.15881761880459336,\n",
       " 0.15875055613906905,\n",
       " 0.15868394233218672,\n",
       " 0.15861776916196665,\n",
       " 0.15855202858236603,\n",
       " 0.15848671271940737,\n",
       " 0.15842181386738877,\n",
       " 0.15835732448517756,\n",
       " 0.15829323719258404,\n",
       " 0.15822954476681328,\n",
       " 0.15816624013899583,\n",
       " 0.1581033163907925,\n",
       " 0.15804076675107523,\n",
       " 0.15797858459267958,\n",
       " 0.15791676342922886,\n",
       " 0.15785529691202854,\n",
       " 0.1577941788270289,\n",
       " 0.15773340309185482,\n",
       " 0.15767296375290166,\n",
       " 0.15761285498249475,\n",
       " 0.15755307107611288,\n",
       " 0.15749360644967278,\n",
       " 0.15743445563687417,\n",
       " 0.15737561328660427,\n",
       " 0.15731707416039992,\n",
       " 0.15725883312996633,\n",
       " 0.15720088517475136,\n",
       " 0.15714322537957418,\n",
       " 0.15708584893230676,\n",
       " 0.15702875112160725,\n",
       " 0.15697192733470494,\n",
       " 0.1569153730552333,\n",
       " 0.15685908386111344,\n",
       " 0.15680305542248407,\n",
       " 0.15674728349967793]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1de2baa98b0>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
